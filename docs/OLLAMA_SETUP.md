# FA Report Analyzer v2.0 - Ollama å®‰è£èˆ‡é…ç½®æŒ‡å—

## ğŸ“¦ ä»€éº¼æ˜¯ Ollamaï¼Ÿ

Ollama æ˜¯ä¸€å€‹å¯ä»¥åœ¨æœ¬åœ°é‹è¡Œå¤§å‹èªè¨€æ¨¡å‹çš„å·¥å…·ï¼Œè®“ä½ å¯ä»¥ï¼š
- ğŸ”’ **å®Œå…¨æœ¬åœ°åŒ–** - æ•¸æ“šä¸é›¢é–‹ä½ çš„é›»è…¦
- ğŸ’° **å®Œå…¨å…è²»** - ç„¡éœ€ API è²»ç”¨
- âš¡ **å¿«é€ŸéŸ¿æ‡‰** - æœ¬åœ°æ¨ç†ï¼Œç„¡ç¶²è·¯å»¶é²
- ğŸ¯ **æ”¯æ´å¤šæ¨¡æ…‹** - å¯ä»¥åˆ†ææ–‡å­—å’Œåœ–ç‰‡

## ğŸš€ å¿«é€Ÿå®‰è£ Ollama

### Linux ç³»çµ±

```bash
# 1. å®‰è£ Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. å•Ÿå‹• Ollama æœå‹™
ollama serve

# 3. ä¸‹è¼‰æ”¯æ´è¦–è¦ºçš„æ¨¡å‹ (å¦é–‹çµ‚ç«¯åŸ·è¡Œ)
ollama pull llama3.2-vision:latest
```

### macOS ç³»çµ±

```bash
# 1. ä½¿ç”¨ Homebrew å®‰è£
brew install ollama

# æˆ–ä¸‹è¼‰ .dmg å®‰è£åŒ…
# https://ollama.com/download

# 2. å•Ÿå‹• Ollama
ollama serve

# 3. ä¸‹è¼‰æ¨¡å‹
ollama pull llama3.2-vision:latest
```

### Windows ç³»çµ±

1. ä¸‹è¼‰å®‰è£ç¨‹å¼: https://ollama.com/download
2. åŸ·è¡Œå®‰è£ç¨‹å¼
3. é–‹å•Ÿå‘½ä»¤æç¤ºå­—å…ƒ
4. åŸ·è¡Œ: `ollama pull llama3.2-vision:latest`

## ğŸ¯ æ¨è–¦æ¨¡å‹

### æ”¯æ´è¦–è¦ºåˆ†æçš„æ¨¡å‹

| æ¨¡å‹åç¨± | å¤§å° | ç‰¹é» | æ¨è–¦ç”¨é€” |
|---------|------|------|----------|
| **llama3.2-vision:latest** | ~8GB | Meta æœ€æ–°è¦–è¦ºæ¨¡å‹ | â­ æ¨è–¦ç”¨æ–¼ FA å ±å‘Šåˆ†æ |
| llama3.2-vision:90b | ~50GB | è¶…å¤§å‹è¦–è¦ºæ¨¡å‹ | é«˜ç²¾åº¦åˆ†æï¼ˆéœ€è¦å¼·å¤§ç¡¬é«”ï¼‰|
| llava:13b | ~8GB | ç©©å®šçš„è¦–è¦ºæ¨¡å‹ | å‚™é¸æ–¹æ¡ˆ |
| bakllava:latest | ~5GB | è¼•é‡ç´šè¦–è¦ºæ¨¡å‹ | ä½é…ç½®é›»è…¦ |

### ç´”æ–‡å­—æ¨¡å‹ï¼ˆç„¡åœ–ç‰‡åˆ†æï¼‰

| æ¨¡å‹åç¨± | å¤§å° | ç‰¹é» |
|---------|------|------|
| llama3.1:8b | ~4.7GB | å¿«é€Ÿã€é«˜æ•ˆ |
| llama3.1:70b | ~40GB | é«˜ç²¾åº¦ |
| qwen2.5:14b | ~9GB | ä¸­æ–‡å‹å¥½ |

## ğŸ“¥ ä¸‹è¼‰æ¨¡å‹

```bash
# ä¸‹è¼‰æ¨è–¦çš„è¦–è¦ºæ¨¡å‹
ollama pull llama3.2-vision:latest

# æŸ¥çœ‹å·²å®‰è£çš„æ¨¡å‹
ollama list

# æ¸¬è©¦æ¨¡å‹
ollama run llama3.2-vision:latest "åˆ†æé€™å¼µåœ–ç‰‡"
```

## ğŸ”§ Python ç’°å¢ƒè¨­ç½®

### å®‰è£å¿…è¦å¥—ä»¶

```bash
# åŸºæœ¬å¥—ä»¶
pip install ollama pandas --break-system-packages

# åœ–ç‰‡è™•ç†
pip install Pillow --break-system-packages

# PDF æ”¯æ´
pip install PyPDF2 PyMuPDF --break-system-packages

# Word æ”¯æ´
pip install python-docx --break-system-packages

# PowerPoint æ”¯æ´
pip install python-pptx --break-system-packages
```

### ä¸€éµå®‰è£æ‰€æœ‰å¥—ä»¶

```bash
pip install ollama pandas Pillow PyPDF2 PyMuPDF python-docx python-pptx --break-system-packages
```

## ğŸ¯ ä½¿ç”¨æ–¹å¼

### 1. ä½¿ç”¨ Ollama (é è¨­ï¼Œæ¨è–¦)

```bash
# ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ
ollama serve

# åœ¨å¦ä¸€å€‹çµ‚ç«¯åŸ·è¡Œåˆ†æ
python fa_report_analyzer_v2.py -i fa_report.pdf
```

### 2. ä½¿ç”¨ OpenAI API

```bash
python fa_report_analyzer_v2.py -i report.pdf -b openai -k YOUR_API_KEY
```

### 3. ä½¿ç”¨ Anthropic Claude

```bash
python fa_report_analyzer_v2.py -i report.pdf -b anthropic -k YOUR_API_KEY
```

## âš™ï¸ ç³»çµ±éœ€æ±‚

### Ollama ç¡¬é«”éœ€æ±‚

| æ¨¡å‹å¤§å° | RAM | GPU (å¯é¸) | ç¡¬ç¢Ÿç©ºé–“ |
|---------|-----|-----------|---------|
| 7B åƒæ•¸ | 8GB | 4GB VRAM | 5GB |
| 13B åƒæ•¸ | 16GB | 8GB VRAM | 10GB |
| 70B åƒæ•¸ | 64GB | 40GB VRAM | 50GB |

### æ¨è–¦é…ç½®ï¼ˆFA å ±å‘Šåˆ†æï¼‰

- **CPU**: 4 æ ¸å¿ƒä»¥ä¸Š
- **RAM**: 16GB ä»¥ä¸Š
- **ç¡¬ç¢Ÿ**: 20GB å¯ç”¨ç©ºé–“
- **GPU**: NVIDIA GPUï¼ˆå¯é¸ï¼ŒæœƒåŠ é€Ÿæ¨ç†ï¼‰

## ğŸ” é©—è­‰å®‰è£

```bash
# æª¢æŸ¥ Ollama æ˜¯å¦å®‰è£
ollama --version

# æª¢æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹è¼‰
ollama list

# æ¸¬è©¦æ¨¡å‹
ollama run llama3.2-vision:latest "ä½ å¥½"

# æª¢æŸ¥ Python å¥—ä»¶
python -c "import ollama; print('Ollama SDK å·²å®‰è£')"
```

## ğŸ¨ æ”¯æ´çš„æ–‡ä»¶æ ¼å¼

### æ–‡å­—æ ¼å¼
- âœ… TXT - ç´”æ–‡å­—
- âœ… PDF - å«æ–‡å­—å’Œåœ–ç‰‡
- âœ… DOCX/DOC - Word æ–‡ä»¶å«åœ–ç‰‡
- âœ… PPTX/PPT - PowerPoint å«åœ–ç‰‡

### åœ–ç‰‡æ ¼å¼
- âœ… JPG/JPEG
- âœ… PNG
- âœ… GIF
- âœ… WEBP

## ğŸ’¡ ä½¿ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1: åˆ†æç´”æ–‡å­—å ±å‘Š

```bash
python fa_report_analyzer_v2.py -i sample_fa_report.txt
```

### ç¯„ä¾‹ 2: åˆ†æ PDFï¼ˆå«åœ–ç‰‡ï¼‰

```bash
python fa_report_analyzer_v2.py -i fa_report_with_images.pdf
```

### ç¯„ä¾‹ 3: åˆ†æåœ–ç‰‡æ–‡ä»¶

```bash
python fa_report_analyzer_v2.py -i failure_image.jpg
```

### ç¯„ä¾‹ 4: åˆ†æ PowerPoint

```bash
python fa_report_analyzer_v2.py -i fa_presentation.pptx
```

### ç¯„ä¾‹ 5: æŒ‡å®šè¼¸å‡ºæ–‡ä»¶

```bash
python fa_report_analyzer_v2.py -i report.pdf -o my_evaluation.txt
```

### ç¯„ä¾‹ 6: ä½¿ç”¨ä¸åŒçš„æ¨¡å‹

```bash
python fa_report_analyzer_v2.py -i report.pdf -m llava:13b
```

## ğŸ”§ é€²éšé…ç½®

### è‡ªè¨‚ Ollama é…ç½®

ç·¨è¼¯ Ollama é…ç½®æ–‡ä»¶ï¼ˆLinux/Mac: `~/.ollama/config.json`ï¼‰:

```json
{
  "models_path": "/path/to/models",
  "keep_alive": "5m",
  "num_parallel": 4
}
```

### GPU åŠ é€Ÿ

å¦‚æœæœ‰ NVIDIA GPU:

```bash
# æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨
nvidia-smi

# Ollama æœƒè‡ªå‹•ä½¿ç”¨ GPU
# æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…æ³
watch -n 1 nvidia-smi
```

## ğŸš¨ å¸¸è¦‹å•é¡Œ

### Q1: Ollama æœå‹™ç„¡æ³•å•Ÿå‹•

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# æª¢æŸ¥ç«¯å£æ˜¯å¦è¢«ä½”ç”¨
lsof -i :11434

# é‡æ–°å•Ÿå‹•æœå‹™
pkill ollama
ollama serve
```

### Q2: æ¨¡å‹ä¸‹è¼‰å¤±æ•—

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# ä½¿ç”¨é¡åƒæº
export OLLAMA_MODELS=/path/to/models
ollama pull llama3.2-vision:latest
```

### Q3: è¨˜æ†¶é«”ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ:**
- ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆå¦‚ llama3.2-vision:latest è€Œä¸æ˜¯ :90bï¼‰
- å¢åŠ ç³»çµ±äº¤æ›ç©ºé–“
- é—œé–‰å…¶ä»–ä½”ç”¨è¨˜æ†¶é«”çš„ç¨‹å¼

### Q4: åœ–ç‰‡ç„¡æ³•è§£æ

**è§£æ±ºæ–¹æ¡ˆ:**
```bash
# ç¢ºä¿å®‰è£äº†åœ–ç‰‡è™•ç†å¥—ä»¶
pip install Pillow PyMuPDF python-docx python-pptx --break-system-packages

# ä½¿ç”¨æ”¯æ´è¦–è¦ºçš„æ¨¡å‹
ollama pull llama3.2-vision:latest
```

## ğŸ“Š æ€§èƒ½å„ªåŒ–

### æå‡åˆ†æé€Ÿåº¦

1. **ä½¿ç”¨ GPU**: ç¢ºä¿ NVIDIA GPU é©…å‹•æ­£ç¢ºå®‰è£
2. **èª¿æ•´ä¸¦è¡Œæ•¸**: åœ¨ Ollama é…ç½®ä¸­è¨­ç½® `num_parallel`
3. **é ç†±æ¨¡å‹**: å…ˆåŸ·è¡Œä¸€æ¬¡å°æ¸¬è©¦è®“æ¨¡å‹è¼‰å…¥è¨˜æ†¶é«”

### æå‡æº–ç¢ºåº¦

1. **ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹**: å¦‚ llama3.2-vision:90bï¼ˆéœ€è¦æ›´å¤šè³‡æºï¼‰
2. **æä¾›é«˜å“è³ªåœ–ç‰‡**: ç¢ºä¿åœ–ç‰‡æ¸…æ™°ã€è§£æåº¦è¶³å¤ 
3. **å„ªåŒ–æç¤ºè©**: åœ¨ç¨‹å¼ä¸­èª¿æ•´åˆ†ææç¤ºè©

## ğŸ”— åƒè€ƒè³‡æº

- Ollama å®˜ç¶²: https://ollama.com
- Ollama GitHub: https://github.com/ollama/ollama
- æ¨¡å‹åˆ—è¡¨: https://ollama.com/library
- Python SDK: https://github.com/ollama/ollama-python

## ğŸ“ ç‰ˆæœ¬èªªæ˜

- **v2.0**: åŠ å…¥ Ollama æ”¯æ´ã€åœ–ç‰‡åˆ†æåŠŸèƒ½
- **v1.0**: åŸºç¤ç‰ˆæœ¬ï¼Œåƒ…æ”¯æ´ Anthropic Claude

---

**å»ºè­°é…ç½®**: Ollama + llama3.2-vision:latest
**æœ€ä½é…ç½®**: 8GB RAM + 10GB ç¡¬ç¢Ÿç©ºé–“
**æ¨è–¦é…ç½®**: 16GB RAM + NVIDIA GPU + 20GB ç¡¬ç¢Ÿç©ºé–“
